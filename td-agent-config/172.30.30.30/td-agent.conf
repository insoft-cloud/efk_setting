####
## Output descriptions:
##

# Treasure Data (http://www.treasure-data.com/) provides cloud based data
# analytics platform, which easily stores and processes data from td-agent.
# FREE plan is also provided.
# @see http://docs.fluentd.org/articles/http-to-td
#
# This section matches events whose tag is td.DATABASE.TABLE
<match td.*.*>
  @type tdlog
  @id output_td
  apikey YOUR_API_KEY

  auto_create_table
  <buffer>
    @type file
    path /var/log/td-agent/buffer/td
  </buffer>

  <secondary>
    @type file
    path /var/log/td-agent/failed_records
  </secondary>
</match>

## match tag=debug.** and dump to console
<match debug.**>
  @type stdout
  @id output_stdout
</match>

####
## Source descriptions:
##

## built-in TCP input
## @see http://docs.fluentd.org/articles/in_forward
<source>
  @type forward
  @id input_forward
  port 24224
  add_tag_prefix k8s
</source>

<source>
  @type forward
  port 24225
  add_tag_prefix myvm
</source>

<match k8s.**>
   @type elasticsearch
   @id elasticsearch      
   host 127.0.0.1  
   port 9200      
   logstash_format true        #이렇게 하면 ES에 로그를 저장할 수 있고, Kibana를 이용할 수 있다. (default : flase)
   logstash_prefix fluentd     #Set index name (default : fluentd)
   include_tag_key true        #Include tag key (logname)
   tag_key @logname            #Include logname
            
   <buffer>
     @type file                #chunk wirte at file (default: memory)
     path /var/log/td-agent/elasticsearch.buffer    #chunk path
     flush_mode interval              
     retry_type exponential_backoff   
     flush_thread_count 2       
     flush_interval 1s         #chunk가 queue로 이동 flush 하는 간격(chunk limit 값에따라  interval 간격에 의해 데이터가 queue로 이동)  
     retry_max_interval 30    
     chunk_limit_size 256m     
     queue_limit_length 256    #chunk는 output으로 이동하기 전에 queue에서 대기하는데 이 큐에 쌓일 수 있는 청크의 개수를 의미
     overflow_action block
#    retry_wait 5
#    queue_full_action drop_oldest_chunk        
   </buffer>  
</match>

<match myvm.**>
   @type copy
   <store>
      @type stdout
   </store>
   <store>
     @type elasticsearch
     @id vmes
     host 127.0.0.1
     port 9200
     logstash_format true
     logstash_prefix myvm
   </store>
</match>

## built-in UNIX socket input
#<source>
#  type unix
#</source>

# HTTP input
# POST http://localhost:8888/<tag>?json=<json>
# POST http://localhost:8888/td.myapp.login?json={"user"%3A"me"}
# @see http://docs.fluentd.org/articles/in_http
<source>
  @type http
  @id input_http
  port 8888
</source>

## live debugging agent
<source>
  @type debug_agent
  @id input_debug_agent
  bind 127.0.0.1
  port 24230
</source>

#<source>
#  @type monitor_agent
#  bind 0.0.0.0
#  port 24220 
#</source>

####
## Examples:
##

## File input
## read apache logs continuously and tags td.apache.access
#<source>
#  @type tail
#  @id input_tail
#  <parse>
#    @type apache2
#  </parse>
#  path /var/log/httpd-access.log
#  tag td.apache.access
#</source>

## File output
## match tag=local.** and write to file
#<match local.**>
#  @type file
#  @id output_file
#  path /var/log/td-agent/access
#</match>

## Forwarding
## match tag=system.** and forward to another td-agent server
#<match system.**>
#  @type forward
#  @id output_system_forward
#
#  <server>
#    host 192.168.0.11
#  </server>
#  # secondary host is optional
#  <secondary>
#    <server>
#      host 192.168.0.12
#    </server>
#  </secondary>
#</match>

## Multiple output
## match tag=td.*.* and output to Treasure Data AND file
#<match td.*.*>
#  @type copy
#  @id output_copy
#  <store>
#    @type tdlog
#    apikey API_KEY
#    auto_create_table
#    <buffer>
#      @type file
#      path /var/log/td-agent/buffer/td
#    </buffer>
#  </store>
#  <store>
#    @type file
#    path /var/log/td-agent/td-%Y-%m-%d/%H.log
#  </store>
#</match>
